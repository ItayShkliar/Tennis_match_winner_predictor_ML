# Tennis_match_winner_predictor_ML

סיכום העבודה
בחירת הנושא:

לא הייתה לי דילמה קשה בבחירת הנושא כי ישר בחרתי את מה שאני מאוד אוהב - טניס. אני משחק טניס וזה מאוד עניין אותי איך לחזות ניצחונות וקיוויתי שאוכל להשתמש בתוצאות שלי בעצמי.

הנושא הוא חזיית ניצחון של משחקי טניס

השגת הנתונים:

תחילה ניסיתי במשך שעות למצוא נתונים שיעזרו לי באינטרנט אך לא הצלחתי למצוא, החלטתי לא לוותר כי התחברתי מאוד לנושא ולהשיג את הנתונים בעצמי.

בשביל להשיג את הנתונים לקחתי מידע מהאתר ATP TOUR בעזרת סקרייפינג

בסקרייפינג בהתחלה השתמשתי בספריות lxml selenium ולאחר מכן נתקלתי בבעיה עם האתר ובשביל לפתור את הבעיה השתמשתי בchromedriver

לאחר מכן שילבתי טבלאות נתונים של 3 שנים יחד 2020 ,2021, 2022

ניקוי הנתונים:

הנתונים שלי היו בנויים כך: בכל שורה היה משחק אחד ובשורה היו נתונים של המפסיד ושל המנצח.

הורדתי את העמודות הלא חשובות בנתונים למשל: שם הטורניר, קישור למשחק, קישור לשחקן ועוד.

נתקלתי בבעיה ולא ידעתי איך להפוך את הנתונים שלי לברי אימון, לאחר חשיבה רבה זאת הדרך שהשתמשתי בה:

בשביל שיהיה אפשר לאמן את הנתונים יצרתי שורה חדשה לאחר כל שורה קיימת ,הפרדתי את הנתונים של המנצח והמפסיד והכנסתי אותם לשורות שונות והוספתי עמודה חדשה של winner שאם השחקן בשורה זאת הוא המנצח אז כתוב 1 ואם הוא המפסיד אז כתוב 0.

חקר נתונים:

בתחילת חקר הנתונים השתמשתי בפונקציה groupby mean, הפונקציה הזאת מחשבת ממוצע של הערכים בעמודות שבטבלה לפי עמודה אחת, למשל מראה ממוצע של ניצחון(בין 0 ל1) למספר נקודות שהשחק ניצח.

הסקתי מספר מסקנות משימושה:

ככל ששחקן חובט יותר אייסים(הגשה ראשונה שהשחקן היריב לא הצליח לגעת בכדור) כך יש לו סיכוי גבוה יותר לניצחון.

בשביל לנצח הכי חשוב לנצח את הנקודות המכריעות ולא מספיק רק להגיע אליהן

לאחר מכן עשיתי ויזואליזציה של הנתונים בעזרת seaborn הסקתי מהגרפים שיצאו מספר מסקנות:

בשביל לנצח לא בהכרח צריך לנצח יותר נקודות מהיריב, לפעמים המפסיד מנצח יותר נקודות מהיריב. הנקודות המכריעות הם הכי חשובות לניצחון.

ניצחון בנקודות של סרב ראשון ונקודות של סרב שני חשובות באותה מידה, בכל אחד בשביל לנצח צריך לנצח קצת יותר מהיריב.

בשביל לנצח חשוב מאוד לא להביא ליריב ברייק פוינט, בשביל לנצח צריך לשלוט טוב בסרבים ולנצח נקודות חשובות בגיימים של סרב.

לאחר מכן עשיתי מתאם נתונים (מדד סטטי המבטא את הקשר בין שני משתנים) שעזר לי מאוד בהבנת הנתונים לעומק.

אימון:

חלוקת מאגר נתונים לסט אימון וסט בדיקה בשביל לאמן את מודל KNN על חלק מהנתונים ולבדוק את ביצועיו על חלק נפרד שלא נכלל באימון, כדי להעריך את יכולת ההכללה שלו. ביצעתי זאת עם הפונקציה train_test_split של ספריית scikit-learn. חילקתי ביחס של 80 ו20 אחוז, 80 לאימון ו20 לבדיקה.

אלה התוצאות מהאימון הראשונה באלגוריתם knn עם n-neighbors של 12.

           support  precision    recall  f1-score

       0     0.9241    0.9180    0.9211      2294
       1     0.9174    0.9235    0.9205      2262

accuracy                         0.9208      4556
macro avg     0.9208    0.9208    0.9208      4556
weighted avg     0.9208    0.9208    0.9208      4556
התוצאות יצאו טובות מדי אז בדקתי איזה נתון משפיע הכי הרבה על התוצאות.

עשיתי זאת בעזרת קוד מאמן מודל KNN על נתוני האימון ובודק את חשיבות התכונות באמצעות permutation importance. הוא מחשב את השינוי בדיוק המודל כאשר משנים ערכי תכונה מסוימת, ומדפיס את חשיבות כל תכונה בסדר יורד עם הממוצע והסטיית התקן של השינוי. כך ניתן להבין אילו תכונות משפיעות יותר על ביצועי המודל.

אלה הנתונים שמשפיעים הכי הרבה על המודל והתוצאות שיצאו:

serve_rating: 0.212 +/- 0.004

return_rating: 0.167 +/- 0.004

total_points_won: 0.051 +/- 0.003

הורדתי את עמודות אלה בשביל שיהיו תוצאות ריאליסטיות יותר

אלה התוצאות שיצאו לאחר הורדת עמודות אלה:

            support  precision    recall  f1-score  

       0     0.8954    0.8919    0.8936      2294
       1     0.8908    0.8943    0.8926      2262

accuracy                         0.8931      4556
macro avg     0.8931    0.8931    0.8931      4556
weighted avg     0.8931    0.8931    0.8931      4556
דיוק המודל ירד ב2 אחוז

לאחר מכן השתמשתי בקוד המבצע חיפוש רשת (GridSearchCV) על מודל KNN עם פרמטרים שונים כדי למצוא את השילוב הטוב ביותר באמצעות אימות צולב (cross-validation). הוא מנסה כל שילוב של פרמטרים מ-parameters, מאמן את המודל על נתוני האימון, ושומר את התוצאות ב-DataFrame. לבסוף, הוא מדפיס את הזמן שלקח לבצע את החיפוש ומציג את התוצאה הראשונה של החיפוש.

תוצאות של הפרמטרים הכי טובים:

            support  precision    recall  f1-score  

       0       0.94      0.95      0.95      2294
       1       0.95      0.94      0.94      2262

accuracy                           0.95      4556
macro avg       0.95      0.95      0.95      4556
weighted avg       0.95      0.95      0.95      4556
בדיקת הסקלר עם התוצאות הכי טובות. הסקלר שנבחר מתאים את הנתונים (מנרמל אותם) לפני אימון מודל ה-KNN. חיפוש רשת (GridSearchCV) מתבצע למציאת הפרמטרים הטובים ביותר למודל ה-KNN, ולאחר מכן המודל מאומן עם הפרמטרים האלו על הנתונים המותאמים. לבסוף, המודל נבדק והדיוק שלו על סט הבדיקה מוצג. הסקלר עם הדיוק הגבוה ביותר היה המנרמל.

לא נצרך איזון תגיות כי יש בנתונים אותו מספר מנצחים ומפסידים.

התאמת יתר לבדיקת הk (n-neighbor) האופטימלי

המסקנות מהתוצאות לגבי התאמת יתר הן:

התאמת יתר בערכים נמוכים של ( k ): עבור ( k = 1 ), הדיוק באימון הוא 100% בעוד שהדיוק בבדיקה הוא 93%, מה שמעיד על התאמת יתר.
שיפור ויציבות בערכים גבוהים יותר של ( k ): הדיוק בבדיקה משתפר ומתייצב על 90% כאשר ( k ) גדול מ-13, בעוד שהדיוק באימון יורד במקצת, מה שמצביע על הפחתת התאמת יתר.
בחירת ( k ) אופטימלית: ( k = 13 ) ומעלה נראים כערכים אופטימליים, שכן הם משיגים דיוק יציב בבדיקה של 90%.
בגדול, הערכים הגבוהים יותר של ( k ) מונעים התאמת יתר ומביאים לדיוק יציב ואופטימלי.

תוצאות לערכי k גדולים מ13:

            support  precision    recall  f1-score  

       0       0.90      0.89      0.90      2294
       1       0.89      0.90      0.90      2262

accuracy                           0.90      4556
macro avg       0.90      0.90      0.90      4556
weighted avg       0.90      0.90      0.90      4556
אלגוריתם נוסף - svm - תוצאות:

precision    recall  f1-score    support

Winner       0.95      0.96      0.96      2294
Loser       0.96      0.95      0.96      2262

accuracy                           0.96      4556
macro avg       0.96      0.96      0.96      4556
weighted avg       0.96      0.96      0.96      4556
תוצאות יותר טובות מהאלגוריתם knn
